{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "###\n",
    "\n",
    "def plot(label, label_f, prediction, sigma_test, prediction_f, sigma_test_f, window_size, p_value, num_plot = 8, \n",
    "            y_range = None, y_range_f = None, forget_gate=None, forget_gate_f=None):\n",
    "    x = np.arange(192)\n",
    "    pred_minus_sigma = prediction - sigma_test\n",
    "    pred_minus_sigma_f = prediction_f - sigma_test_f\n",
    "    pred_plus_sigma = prediction + sigma_test\n",
    "    pred_plus_sigma_f = prediction_f + sigma_test_f\n",
    "    f = plt.figure(figsize=(50,32))\n",
    "\n",
    "    base_1 = num_plot/2\n",
    "    base_2 = 2\n",
    "\n",
    "    for i in range(int(num_plot/2)):\n",
    "\n",
    "        label_temp = label[i].reshape([window_size,])\n",
    "        label_temp_f = label_f[i].reshape([window_size,])\n",
    "        pred_temp = prediction[i].reshape([window_size,])\n",
    "        pred_temp_f = prediction_f[i].reshape([window_size,])\n",
    "        p_value_temp = p_value[i].reshape([window_size,])\n",
    "        if forget_gate != None:\n",
    "            forget_gate_temp = forget_gate[i].reshape([window_size,])\n",
    "        if forget_gate_f != None:\n",
    "            forget_gate_temp_f = forget_gate_f[i].reshape([window_size,])\n",
    "                \n",
    "        # no forget_gate\n",
    "\n",
    "        plt.subplot(base_1, base_2, i*2+1)\n",
    "        labels, = plt.plot(x,label_temp, color='b')\n",
    "        preds, = plt.plot(x,pred_temp, color='r')\n",
    "        stddev = plt.fill_between(x, pred_minus_sigma[i].reshape([window_size,]) ,\n",
    "                                 pred_plus_sigma[i].reshape([window_size,])  ,\n",
    "                                 color='blue',\n",
    "                                 alpha=0.2)\n",
    "        if forget_gate != None:\n",
    "            forget_gates, = plt.plot(x, forget_gate_temp, color='g')\n",
    "            plt.legend(handles = [labels, preds, stddev, forget_gates], labels = ['Ground_truth', 'Prediction', 'Single stddev ', 'forget_gate'], loc = 'upper left', fontsize =12)\n",
    "        else:\n",
    "            plt.legend(handles = [labels, preds, stddev], labels = ['Ground_truth', 'Prediction', 'Single stddev '], loc = 'upper left', fontsize =12)\n",
    "        plt.axvline(168, color='k', linestyle = \"dashed\")\n",
    "        #参考线\n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(axis = 'x', which = 'major', labelsize = 24)\n",
    "        ax.tick_params(axis = 'y', which = 'major', labelsize = 24)\n",
    "        axes = plt.gca()\n",
    "        if y_range:  axes.set_ylim(y_range)\n",
    "\n",
    "        # forget_gate\n",
    "\n",
    "        plt.subplot(base_1, base_2, i*2+2)\n",
    "        labels, = plt.plot(x,label_temp_f, color='b')\n",
    "        preds, = plt.plot(x,pred_temp_f, color='r')\n",
    "        stddev_f = plt.fill_between(x, pred_minus_sigma_f[i].reshape([window_size,]) ,\n",
    "                                 pred_plus_sigma_f[i].reshape([window_size,])  ,\n",
    "                                 color='blue',\n",
    "                                 alpha=0.2)\n",
    "        if forget_gate_f != None:\n",
    "            forget_gates, = plt.plot(x, forget_gate_temp_f, color='g')\n",
    "            plt.legend(handles = [labels, preds, stddev_f, forget_gates], labels = ['Ground_truth', 'Prediction', 'Single stddev ', 'forget_gate'], loc = 'upper left', fontsize =12)\n",
    "        else:\n",
    "            plt.legend(handles = [labels, preds, stddev_f], labels = ['Ground_truth', 'Prediction', 'Single stddev '], loc = 'upper left', fontsize =12)\n",
    "        plt.axvline(168, color='k', linestyle = \"dashed\")\n",
    "        #参考线\n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(axis = 'x', which = 'major', labelsize = 24)\n",
    "        ax.tick_params(axis = 'y', which = 'major', labelsize = 24)\n",
    "        axes = plt.gca()\n",
    "        if y_range:  axes.set_ylim(y_range_f)\n",
    "\n",
    "def compute_new_v(values):\n",
    "    v = np.mean(values)+1\n",
    "    return v\n",
    "    \n",
    "def rescale(values, v_old, v_new):\n",
    "    values_temp = values*v_old\n",
    "    return np.true_divide(values_temp, v_new)\n",
    "\n",
    "def compute_forget_index(p_values): \n",
    "    #compute the index of the last change point\n",
    "    index_list = []\n",
    "    for serie in range(p_values.shape[0]):\n",
    "        for i in reversed(range(p_values.shape[1])): #from 191 to 0\n",
    "            if p_values[serie,i,0]==0: \n",
    "                index_list.append(i)\n",
    "                break\n",
    "            elif i==0:\n",
    "                index_list.append(-1)\n",
    "    index = np.array(index_list)\n",
    "    return index #shape = [64,]\n",
    "                \n",
    "                \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    checkpoint_dir = \"../checkpoint/checkpoint_forget/\"\n",
    "    '''\n",
    "    #CNN\n",
    "    checkpoint_dir = \"../checkpoint/checkpoint_CNN/\"\n",
    "    '''\n",
    "    #ckpt包含所有checkpoint信息和最新checkpoint信息\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    print(ckpt)\n",
    "    # ckpt.model_checkpoint_path是最新checkpoint的名字，加上\".meta\"即可用于导入graph\n",
    "    if (ckpt and ckpt.model_checkpoint_path):\n",
    "        #加载计算图\n",
    "        saver = tf.train.import_meta_graph(ckpt.model_checkpoint_path+\".meta\")\n",
    "        #加载参数\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"No model can be load!\")\n",
    "\n",
    "    train_op = tf.get_collection('train_op')[0]\n",
    "    label = tf.get_collection(\"label\")[0]\n",
    "\n",
    "    miu_train = tf.get_collection(\"miu_train\")[0]\n",
    "    sigma_train = tf.get_collection(\"sigma_train\")[0]\n",
    "    RMSE_train = tf.get_collection(\"RMSE_train\")[0]\n",
    "    ND_train = tf.get_collection(\"ND_train\")[0]\n",
    "\n",
    "    miu_pred = tf.get_collection(\"miu_pred\")[0]\n",
    "    sigma_pred = tf.get_collection(\"sigma_pred\")[0]\n",
    "    RMSE_pred = tf.get_collection(\"RMSE_pred\")[0]\n",
    "    ND_pred = tf.get_collection(\"ND_pred\")[0]\n",
    "    hidden_states_all = tf.get_collection(\"hidden_states_all\")[0] # shape: [2, batch_size, hidden_unit, window_size] = [2, 64, 40, 192]\n",
    "    #forget_gate_all = tf.get_collection(\"forget_gate_all\")[0] #shape: [batch_size, window_size=192, hidden_unit=40]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    def test_step(x_batch, onehot_batch, y_batch, v_batch, batch_size, forget_gate_mask):\n",
    "        feed_dict ={\n",
    "        'input_x:0': x_batch, \n",
    "        'input_onehot:0': onehot_batch,\n",
    "        'input_y:0': y_batch,\n",
    "        'input_v:0' :v_batch,\n",
    "        'input_batch:0': batch_size,\n",
    "        \"forget_gate_mask:0\": forget_gate_mask,\n",
    "        }\n",
    "        RMSE_test, ND_test, miu_test, sigma_test, hidden_states_all_test, = sess.run([RMSE_pred,\n",
    "        #RMSE_test, ND_test, miu_test, sigma_test, hidden_states_all_test, forget_gate_all_test = sess.run([RMSE_pred,\n",
    "                                                            ND_pred,\n",
    "                                                            miu_pred,\n",
    "                                                            sigma_pred,\n",
    "                                                            hidden_states_all,\n",
    "                                                            forget_gate_all,], \n",
    "                                                            feed_dict = feed_dict)\n",
    "        \n",
    "\n",
    "        \n",
    "        return (RMSE_test, ND_test, miu_test, sigma_test, hidden_states_all_test)\n",
    "        #return (RMSE_test, ND_test, miu_test, sigma_test, hidden_states_all_test, forget_gate_all)\n",
    "\n",
    "\n",
    "    shift_train_data = np.load(\"../data/Electricity/elect_pre_train_data.npy\")\n",
    "    shift_train_onehot = np.load(\"../data/Electricity/elect_train_onehot.npy\")\n",
    "    v_all = np.load(\"../data/Electricity/elect_train_v.npy\")\n",
    "    shift_train_label = np.load(\"../data/Electricity/elect_train_label.npy\")\n",
    "    param = np.load(\"../data/Electricity/elect_train_param.npy\")\n",
    "    index_list = np.load(\"../data/Electricity/elect_train_index.npy\")\n",
    "    indexs_pred = np.load(\"../data/Electricity/elect_train_pred_index.npy\")\n",
    "    \n",
    "    '''\n",
    "    #huawei\n",
    "    shift_train_data = np.load(\"../data/huawei/shift_train_data.npy\")\n",
    "    shift_train_onehot = np.load(\"../data/huawei/shift_train_onehot.npy\")\n",
    "    v_all = np.load(\"../data/huawei/v.npy\")\n",
    "    shift_train_label = np.load(\"../data/huawei/shift_train_label.npy\")\n",
    "    param = np.load(\"../data/huawei/param.npy\")\n",
    "    index_list = np.load(\"../data/huawei/indexs_list.npy\")\n",
    "    indexs_pred_list = np.load(\"../huawei/data/indexs_pred_list.npy\")\n",
    "\n",
    "\n",
    "    '''\n",
    "    window_size = param[7]\n",
    "    indexs_pred = [410688, 324890, 81043, 269732, 382203, 421931, 363429, 517402]\n",
    "    indexs_pred = [i+1058 for i in range(64)]\n",
    "    #indexs_pred = [i+498 for i in range(64)]\n",
    "\n",
    "    input_x_batch_pred = shift_train_data[indexs_pred]\n",
    "    input_onehot_batch_pred =shift_train_onehot[indexs_pred]\n",
    "    input_v_batch_pred = v_all[indexs_pred]\n",
    "    input_y_batch_pred = shift_train_label[indexs_pred]\n",
    "    input_y_batch_pred = np.asfarray(input_y_batch_pred, float)\n",
    "    batch_size_pred = len(indexs_pred)\n",
    "    \n",
    "    shift_train_pvalue = np.load(\"../data/Electricity/elect_train_p_value.npy\") #[num_window_all, window_size] last 24 p are strictly 0\n",
    "    shift_train_pvalue_raw = np.copy(shift_train_pvalue) #[num_window_all, window_size]\n",
    "    shift_train_pvalue = np.abs(shift_train_pvalue-1) #shift 0&1\n",
    "    shift_train_pvalue_raw = shift_train_pvalue_raw[indexs_pred]\n",
    "    input_pvalue_batch_pred = shift_train_pvalue[indexs_pred] #[batch_size, window_size]\n",
    "    input_pvalue_batch_pred = np.concatenate([np.expand_dims(input_pvalue_batch_pred, axis=2) for i in range(40)], axis=2) #[batch_size, window_size, 40]\n",
    "    forget_gate_mask_sample = np.full((64, 192, 40), 1, dtype = np.float32) #all 1\n",
    "\n",
    "    \n",
    "    #input_x_batch_pred_period = input_x_batch_pred[2, 0:1, 0] # shape= [24,]\n",
    "    #input_x_batch_pred[2, :, 0] = np.concatenate([input_x_batch_pred_period for i in range(192)], axis = 0) #[192, ]\n",
    "    #input_x_batch_pred[2, 169:, 0]=0\n",
    "    \n",
    "#    RMSE_test, ND_test, miu_test, sigma_test, hidden_states_all_test, forget_gate_all_test = test_step(x_batch = input_x_batch_pred, \n",
    "    RMSE_test, ND_test, miu_test, sigma_test, hidden_states_all_test = test_step(x_batch = input_x_batch_pred, \n",
    "                                                        onehot_batch = input_onehot_batch_pred, \n",
    "                                                        y_batch = input_y_batch_pred, \n",
    "                                                        v_batch = input_v_batch_pred, \n",
    "                                                        batch_size = batch_size_pred,\n",
    "                                                        forget_gate_mask = forget_gate_mask_sample, \n",
    "                                                        )\n",
    "    \n",
    "    input_y_batch_pred_copy = np.copy(input_y_batch_pred)\n",
    "    miu_test_copy = miu_test\n",
    "    sigma_test_copy = sigma_test\n",
    "    \n",
    "    input_y_batch_pred = np.true_divide(input_y_batch_pred, input_v_batch_pred)\n",
    "    miu_test  = np.true_divide(miu_test, input_v_batch_pred)\n",
    "    sigma_test  = np.true_divide(sigma_test, np.sqrt(input_v_batch_pred)) \n",
    "    #forget_gate_all_test = mean(forget_gate_all_test, axis=2) #[batch_size, window_length]\n",
    "    \n",
    "    ## WITH FORGET\n",
    "    # rescale values after the last change point\n",
    "    forget_index = compute_forget_index(input_pvalue_batch_pred) #[64,]\n",
    "    new_v = []\n",
    "    for serie in range(64):\n",
    "        if forget_index[serie] != -1:\n",
    "            index_temp = forget_index[serie]\n",
    "            input_x_batch_pred_new = input_x_batch_pred[serie, index_temp+1:, :] #[new_length, 40]\n",
    "            input_v_new = compute_new_v(input_x_batch_pred_new*input_v_batch_pred[serie])\n",
    "            new_v.append(input_v_new)\n",
    "            input_x_batch_pred_new = rescale(input_x_batch_pred_new, \n",
    "                                             v_old=input_v_batch_pred[serie], \n",
    "                                             v_new=input_v_new, )\n",
    "            input_x_batch_pred[serie, index_temp+1:, :] = input_x_batch_pred_new\n",
    "        else:\n",
    "            new_v.append(input_v_batch_pred[serie])      \n",
    "    new_v = np.array(new_v)\n",
    "    new_v = np.expand_dims(new_v, axis=1) #[batch_size, 1]\n",
    "    \n",
    "    #RMSE_test_f, ND_test_f, miu_test_f, sigma_test_f, hidden_states_all_test_f, forget_gate_all_test_f = test_step(x_batch = input_x_batch_pred,     \n",
    "    RMSE_test_f, ND_test_f, miu_test_f, sigma_test_f, hidden_states_all_test_f = test_step(x_batch = input_x_batch_pred, \n",
    "                                                        onehot_batch = input_onehot_batch_pred, \n",
    "                                                        y_batch = input_y_batch_pred, \n",
    "                                                        v_batch = new_v, \n",
    "                                                        batch_size = batch_size_pred,\n",
    "                                                        forget_gate_mask = input_pvalue_batch_pred, \n",
    "                                                        )\n",
    "    \n",
    "    #miu_test_f  = np.true_divide(miu_test_f, new_v)\n",
    "    #sigma_test_f  = np.true_divide(sigma_test_f, np.sqrt(new_v))\n",
    "    #forget_gate_all_test_f = mean(forget_gate_all_test_f, axis=2) #[batch_size, window_length]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plot(label = input_y_batch_pred, \n",
    "             label_f = input_y_batch_pred_copy,\n",
    "             prediction = miu_test,\n",
    "             sigma_test = sigma_test,\n",
    "             prediction_f =miu_test_f , \n",
    "             sigma_test_f = sigma_test_f, \n",
    "             window_size = 192, \n",
    "             p_value = shift_train_pvalue_raw,\n",
    "             num_plot = 16,\n",
    "             y_range = [-2, 6],\n",
    "#             y_range_f = [-2, 60],\n",
    "             forget_gate=None, \n",
    "             forget_gate_f=None,\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
